# NewLOB

## 对LOB数据理解
在SimLOB中, 作者使用MSE作为目标函数训练模型和校准数据, 即认为LOB中的所有数据具有同样的重要性. 

然而, 事实上LOB中的数据的重要性显然有很大的区别. 
    1. 金融预测相关工作中, 预测金融数据的价格走向( 如, 中间价 ) 占据多数, 可见在LOB中, 一档买卖价量是最重要的特征, 其他档位买卖价量重要性依次递减, 也正因为如此, 所有证券交易市场中必定会提供一档买卖价量供投资者参考,而更多档位的价量则是选择性地提供(可能需要额外的费用或权限). 
    2. 与强化学习中的回报函数类似, 时间越久远的LOB的价值越低, 对于预测金融曲线走向的作用越小, 因此, 在校准过程中单纯的将所有时间步上的LOB数据做MSE也不符合时序数据的这种特征.

综上, 把所有特征一视同仁, 简单地使用MSE作为训练目标显然不是金融背景下地最优选择.

```{admonition} 实验:
:class: tip

1. 为不同特征值人工设置权重参数, 希望训练得到的模型可以抓住数据的主要特征(如一档买卖价量数据)
2. 为不同时间步上的特征添加折扣参数, 让模型倾向于对齐最近的数据, 而放松对历史数据的约束.

```

## LOB订单差

如前所述, 简单地使用MSE判断两个LOB之间的差异是不充分的, 甚至可能是错误的. 理由如下:

1. LOB中的量实际上是价的一个属性, 在MSE中, 只是衡量了相同档位 (而不是相同价格下) 的量的差异, 这个减法在现实中是没有意义的.
2. 不同档位的数据的重要程度是不一样的, 将所有的特征一视同仁直接计算MSE的直接后果是让模型没有重点, 加大了训练难度(模型更难收敛)和所需计算资源.
3. 价和量的重要程度也是不一样的, 价量是不同的单位, 即使在经过归一化处理之后, MSE没有考虑这种差异性.
4. 再次强调, 不同价位的量相减是没有现实意义的. 此外, 不同价位的量代表的意义是完全不同的, 即使是相同价位相减后的值依然不具有直接的可比性, 举一个极端的例子, 100元价位的1手股票, 与1元价位的1手股票, 从量上来看是一样的, 但是价值差别有100倍. 

LOB数据是由订单数据叠加形成的, 本质上是对订单数据的聚合, 任意两个LOB之间的差异都可以视为由若干订单叠加产生的. 证明也很直观, 任何LOB都可以通过下相反的订单消除所有的价量档位到达0的初始状态, 再通过下对应的订单到达另一个LOB. 这些订单可以是很多的小订单( 现实情况下就是如此, 基于Agent的金融模拟器也是)构成的, 如果忽略订单到达的时间步和投资者个体, 可以将相同价位和方向的订单聚合为一个大订单. 这样, 两个LOB之间的订单差就可以唯一确定下来. 

```{admonition} LOB的订单距离: 订单差
:class: note

举例:

1. 两个完全不一致(买卖价全都不一样)的十档LOB至少需要40个聚合订单达成, 将这些订单按照价和买卖方向排列, 就唯一确定了LOB之间的订单差异. 

2. 假设LOB2 由 LOB1 通过若干订单买空一档形成. 那么两个LOB之间的订单差就是一个聚合订单, 该订单的买价为卖一档价, 量等于卖一档的总量. 其他的档位因为价量相同相减之后为0. 即订单差真实反映了两个LOB之间的距离.

```

## Loss函数设计

考虑到在使用Autoencoder中使用重构误差进行训练, 需要两个LOB之间的差异尽量小, 以前的工作使用的Loss函数是通用的MSE方法, 但是如前所述, MSE方法在处理LOB数据时有诸多不足, 本工作提出使用LOB之间的订单差来衡量这一差异. 这一节将详细介绍这一Loss函数的设计.

### NewLOB数据结构
在Related Work中, 已经有人提到了LOB的几种数据结构, 其中最常用两种表示如下:

1. 向量表示, 即SimLOB中的LOB数据结构, 这种结构将十档买卖价量视为一个40维 ($10\times 2 \times 2 $ ) 的向量. 这种表示简单方便, 数据稠密, 但是将价量放在一个向量中, 在进行数据处理时需要更多的实现代码. 
2. 字典表示, 将LOB视为一个键值对列表. 
   ```Python
   [(Buy1, BVolume1),(Buy2, Volume2),...,(Buy10, Volume10), 
    (Sell1,SVolume1),(Sell2,SVolume2),...,(Sell10,SVolume10)]
   ```
   
   这种表示方法明确区分了价量特征, 但是不便于计算. 

本工作基于字典表示, 自定义了LOB的订单差计算伪代码如下:

```Python
input: LOB1,LOB2
output: orders
---
orders = dict(LOB1)
for key, value in dict(LOB2).items():
    if key in diff:
        orders[key]-=value
    else:
        orders[key]=-value

return orders
```

```{admonition} Track
:class: Tip 

将LOB中的买的量改为负值, 其与价格的乘积为负数, 表示下订单需要支出的量, 而卖单则相反, 其与价格的成绩为正, 代表成交后可以收入的金额. 

这样处理之后, 在计算LOB订单差时可以对相同价位的量直接加减(无需考虑买卖方向).
```

这里得到了从LOB1到达LOB2所需的订单的信息, 在训练中希望订单差值尽量小, 但是如前所述, 不同价位的量直接相加是没有意义的. 我们考虑将量与其对应的价格相乘之后,取绝对值和的平均值,或者均方差作为Loss的一部分. 这样这个部分Loss中的每一项单位都代表了金额, 具有现实的可解释性. 因此这一Loss也可以被称为金额Loss. 

```{math}
:label: money_loss
MoneyLoss = \frac{1}{20}\sqrt{\sum_{i=1}^{|orders|}[orders_i(price)\times orders_i(volume)]^2}
```

其中20 代表了20个买卖档位数 ( 如果有相同的档位在实际的`orders`中将会被合并).

换一种角度来思考这个Loss设计, 实际是用价格对订单的量进行了加权, 价格更高的订单, 权重更高, 对投资的影响越大. 

基于上面这个Loss, 会要求模型重构的LOB与真实LOB之间的金额差尽量接近, 如果价位相同且量相同的话, 这一项会被消除(Loss为0), 模型会倾向于输出与原LOB一致的LOB.

为了模型可以加速收敛, 我们可以考虑添加第二项Loss, 要求两个LOB的十档买卖价格对齐. 这一项就是LOB中价格的MSE, 可以被称为价格Loss.

```{math}
:label: price_loss
PriceLoss = \frac{1}{20}\sum_{i=1}^{20}\sigma(i)\sqrt{[LOB_1(prices_i)-LOB_2(prices_i)]^2}
```

其中, $\sigma(i)$ 是关于买卖价格档位的加权系数. 对于校准任务, 该系数恒为 $1.0$, 对于预测任务, 该权重在$i=10$ 和$i=11$处为 $1.0$, 其他位置递减, 如$\sigma(i)=0.9^{|i-10.5|-0.5}$ . 

总Loss如下:
```{math}
:label: loss
Loss = \alpha\cdot MoneyLoss + (1-\alpha)\cdot PriceLoss
```

其中, $\alpha$ 是控制两部分Loss权重的系数, $\alpha$ 越小, 表示模型更注重于买卖价格的对齐, 反之则更关注订单差.

## 下游任务

通过上述Loss训练得到的AutoEncoder可以将LOB映射为一个指定维度的隐向量, 可以用更小的维度表示LOB ( 或者说, 可以提取LOB的主要特征 ), 从而减小下游任务中的计算压力. 对于金融时序数据来说, 常见的下游任务包括:

1. 预测, 即通过一段时间T的LOB数据 ( 如100个连续的LOB数据点) 预测其后一段时间t的LOB\中间价\升降趋势等.
2. 动态检测, 检测一段LOB数据的产生模式是否发生了变化( 变化点的位置 ).
3. 异常检测, 检测一段LOB数据中是否有异常.
4. 校准, 给定一段LOB数据, 调整模拟器参数以获得一段相同( 非常近似 )的数据.

可见, 下游任务多数涉及到更高维度的LOB信息, 在这些任务中, 关注的并非是单个LOB, 而是LOB流 (即添加了时间维度). 因此, 需要设计一个方法, 以判断两个LOB流是否相似. 
一个简单的想法是改进上面针对单个LOB的Loss, 添加一个对时间步的平均. 即:

```{math}
:label: money_losses
MoneyLosses = \frac{1}{20T}\sum_{t=1}^{T}\sqrt{\lambda(t)\cdot\sum_{i=1}^{|orders|}[orders_i^t(price)\times orders_i^t(volume)]^2} 
```

和

```{math}
:label: price_losses
PriceLosses = \frac{1}{20T}\sum_{t=1}^{T}\lambda(t)\cdot \sum_{i=1}^{20}\sigma(i)\sqrt{[LOB_1^t(prices_i)-LOB_2^t(prices_i)]^2}
```

对于LOB流的Losses计算则变为:

```{math}
:label: losses
Losses = \alpha\cdot MoneyLosses + (1-\alpha)\cdot PriceLosses
```

其中, $\lambda(t)$ 是关于时间步的函数, 如果需要考虑不同时间步的LOB对于结果的影响不同, 就可以通过该关于 $t$ 的函数来调整不同时间步的权重. 例如, 在预测任务中, 近期的LOB数据显然比历史LOB数据更具价值, 这个函数可以设置为 $0.99$ 的指数权重; 而在校准任务中, 我们希望所有时间步的LOB都尽量接近, 该函数是值为 $1.0$ 的常函数. 


## 校准





















