# NewLOB

## 对LOB数据理解
在SimLOB中, 作者使用MSE作为目标函数训练模型和校准数据, 即认为LOB中的所有数据具有同样的重要性. 

然而, 事实上LOB中的数据的重要性显然有很大的区别. 
    1. 金融预测相关工作中, 预测金融数据的价格走向( 如, 中间价 ) 占据多数, 可见在LOB中, 一档买卖价量是最重要的特征, 其他档位买卖价量重要性依次递减, 也正因为如此, 所有证券交易市场中必定会提供一档买卖价量供投资者参考,而更多档位的价量则是选择性地提供(可能需要额外的费用或权限). 
    2. 与强化学习中的回报函数类似, 时间越久远的LOB的价值越低, 对于预测金融曲线走向的作用越小, 因此, 在校准过程中单纯的将所有时间步上的LOB数据做MSE也不符合时序数据的这种特征.

综上, 把所有特征一视同仁, 简单地使用MSE作为训练目标显然不是金融背景下地最优选择.

```{admonition} 实验:
:class: tip

1. 为不同特征值人工设置权重参数, 希望训练得到的模型可以抓住数据的主要特征(如一档买卖价量数据)
2. 为不同时间步上的特征添加折扣参数, 让模型倾向于对齐最近的数据, 而放松对历史数据的约束.

```

## LOB订单差

如前所述, 简单地使用MSE判断两个LOB之间的差异是不充分的, 甚至可能是错误的. 理由如下:

1. LOB中的量实际上是价的一个属性, 在MSE中, 只是衡量了相同档位 (而不是相同价格下) 的量的差异, 这个减法在现实中是没有意义的.
2. 不同档位的数据的重要程度是不一样的, 将所有的特征一视同仁直接计算MSE的直接后果是让模型没有重点, 加大了训练难度(模型更难收敛)和所需计算资源.
3. 价和量的重要程度也是不一样的, 价量是不同的单位, 即使在经过归一化处理之后, MSE没有考虑这种差异性.
4. 再次强调, 不同价位的量相减是没有现实意义的. 此外, 不同价位的量代表的意义是完全不同的, 即使是相同价位相减后的值依然不具有直接的可比性, 举一个极端的例子, 100元价位的1手股票, 与1元价位的1手股票, 从量上来看是一样的, 但是价值差别有100倍. 

LOB数据是由订单数据叠加形成的, 本质上是对订单数据的聚合, 任意两个LOB之间的差异都可以视为由若干订单叠加产生的. 证明也很直观, 任何LOB都可以通过下相反的订单消除所有的价量档位到达0的初始状态, 再通过下对应的订单到达另一个LOB. 这些订单可以是很多的小订单( 现实情况下就是如此, 基于Agent的金融模拟器也是)构成的, 如果忽略订单到达的时间步和投资者个体, 可以将相同价位和方向的订单聚合为一个大订单. 这样, 两个LOB之间的订单差就可以唯一确定下来. 

```{admonition} LOB的订单距离: 订单差
:class: note

举例:

1. 两个完全不一致(买卖价全都不一样)的十档LOB至少需要40个聚合订单达成, 将这些订单按照价和买卖方向排列, 就唯一确定了LOB之间的订单差异. 

2. 假设LOB2 由 LOB1 通过若干订单买空一档形成. 那么两个LOB之间的订单差就是一个聚合订单, 该订单的买价为卖一档价, 量等于卖一档的总量. 其他的档位因为价量相同相减之后为0. 即订单差真实反映了两个LOB之间的距离.

```

## Loss函数设计

考虑到在使用Autoencoder中使用重构误差进行训练, 需要两个LOB之间的差异尽量小, 以前的工作使用的Loss函数是通用的MSE方法, 但是如前所述, MSE方法在处理LOB数据时有诸多不足, 本工作提出使用LOB之间的订单差来衡量这一差异. 这一节将详细介绍这一Loss函数的设计.

### NewLOB数据结构
在Related Work中, 已经有人提到了LOB的几种数据结构, 其中最常用两种表示如下:

1. 向量表示, 即SimLOB中的LOB数据结构, 这种结构将十档买卖价量视为一个40维 ($10\times 2 \times 2 $ ) 的向量. 这种表示简单方便, 数据稠密, 但是将价量放在一个向量中, 在进行数据处理时需要更多的实现代码. 
2. 字典表示, 将LOB视为一个键值对列表. 
   ```Python
   [(Buy1, BVolume1),(Buy2, Volume2),...,(Buy10, Volume10), 
    (Sell1,SVolume1),(Sell2,SVolume2),...,(Sell10,SVolume10)]
   ```
   
   这种表示方法明确区分了价量特征, 但是不便于计算. 

本工作基于字典表示, 自定义了LOB的订单差计算伪代码如下:

```Python
input: LOB1,LOB2
output: orders
---
orders = dict(LOB1)
for key, value in dict(LOB2).items():
    if key in diff:
        orders[key]-=value
        if orders[key] == 0.0:
            orders.remove(key)
    else:
        orders[key]=-value

return orders
```

```{admonotion} Track
:class: Tip 

将LOB中的买的量改为负值, 其与价格的乘积为负数, 表示下订单需要支出的量, 而卖单则相反, 其与价格的成绩为正, 代表成交后可以收入的金额. 

这样处理之后, 在计算LOB订单差时可以对相同价位的量直接加减(无需考虑买卖方向).
```

这里得到了从LOB1到达LOB2所需的订单的信息, 在训练中希望订单差值尽量小, 但是如前所述, 不同价位的量直接相加是没有意义的. 我们考虑将量与其对应的价格相乘之后,取绝对值和的平均值,或者均方差作为Loss的一部分. 这样这个部分Loss中的每一项单位都代表了金额, 具有现实的可解释性. 因此这一Loss也可以被称为金额Loss. 

换一种角度来思考这个Loss设计, 实际是用价格对订单的量进行了加权, 价格更高的订单, 权重更高, 对投资的影响越大. 

基于上面这个Loss, 会要求模型重构的LOB与真实LOB之间的金额差尽量接近, 如果价位相同且量相同的话, 这一项会被消除(Loss为0), 模型会倾向于输出与原LOB一致的LOB.

















