# SimLOB中存在的问题

Learning Representations of Limited Order Book for Financial Market Simulation

文章可以参考{cite:p}`li2024simlob`.

## 限价订单簿 LOB


## 1. 数据处理

### 1.1 数据生成中存在的问题

#### 1.1.1 生成ABM模型参数

在Maxe的{ref}`XML 配置文件 <XML_file>`中，除了{ref}`PGPS模型 <PGPS>`所需的6个参数之外，
还有一些（理应）可以影响模型数据生成的参数需要随机产生，以增强训练得到的神经网络的Generalization。

例如：

* `SetupAgent中`:`bidVolume`,`askVolume`,`bidPrice`,`askPrice`, 这四个参数是模型的起始状态(应该属于SimLOB模型中的上下文信息),如果在所有训练数据中都使用相同的参数作为起始值, 模型的泛用性必然遭到质疑, 特别是在面对下游任务为真实数据的情况时.
  
```{admonition} 讨论
:class: note
虽然通过数据预处理中的归一化和正则化处理后, 这些上下文信息在一定程度上能被消除, 但是ABM模型本身可能会基于这些上下文信息下订单, 特别是在比PGPS更复杂的ABM模型中.
```

* `Simulation`中: `random_seed`, 该参数决定了PGPS模型的随机性, 相同参数在不同随机种子下产生的结果可能大相径庭(还需要对Maxe中的PGPS模型进行更深入的研究才可以确定). 但如果考虑模型的随机性, 那么下游的校准任务将变得无比复杂, 这可以在后续的{ref}`Simulation-based Inference  <SBI>` 研究中做进一步讨论.

### 1.2 数据清洗时存在的问题

#### 1.2.1 错误数据
TheSimulator(或者说PGPS模型)并不保证所有生成的数据都是正确的, 即使所有参数都在指定的参数范围之内. 其中一个最典型的错误就是在LOB数据中, 价(量)产生负值, 这在实际中是不可能发生的. 在一次模拟中如果出现负值, 意味着这条数据(在SimLOB实验中为50000个时间点)后面的值都有问题.

SimLOB训练数据是由单条数据按照100时间点长度进行切分的(不重叠的滑动窗口法), 一条错误的模拟最多会向训练数据集中引入500条错误的训练数据. 以现在SimLOB训练数据集原始记录来看, 至少有 $ 66/2000=3.3% $ 条这样的数据. 从训练过程来看, 这些数据点会导致模型不稳定, 并且数量符合前面计算的`3.3%`. 如[下图](error_data)所示:

```{figure} ./imgs/error_data.png
:name: error_data

错误数据对训练造成的影响.
```

从图中可以看出, 在某些batch, 训练过程中的Loss会明显高于其他batch. 并且这些位置不因训练模型的不同而有区别. (因为在DataLoader中使用了相同的随机种子,因此这些出错的batch位置会相同.)


```{admonition} 改进方法:
:class: tip
* 在数据清洗中, 如果数据出现了错误, 就删除整条数据. 
* 记录出错的参数组合(如果后续的其他工作可能用得上).
```


#### 1.2.2 低质量数据
从上面的错误数据来看, Maxe除了生成错误数据外, 肯定还会生成不少低质量的数据, 这些数据虽然符合作为金融数据的约束条件, 但是与实际的金融数据可能相差甚远, 这样的训练数据可能会影响模型的校准能力.

```{admonition} 讨论
:class: note

有几点可以再仔细研究:
1. 如何判断不良数据? (Stylized Factors?)
2. 这些数据与金融市场的异常数据有什么区别和联系? 
    * 是否可以利用这些数据训练模型, 让模型可以检测异常?
```

#### 1.2.3 改善数据集的效果
```{figure} ./imgs/default_data_vs_cleaned_data.png
:name: cleaned_data

对已有的CSV数据做初步清理后的训练结果对比
```
```{figure} ./imgs/default_data_vs_cleaned_data_valid.png
:name: cleaned_data_valid

对已有的CSV数据做初步清理后的验证结果对比
```
从这组对比实验可以看出, 只是清理数据集,对模型的最终效果提升不大, 但是训练的收敛速度更快, 训练过程更平稳(中间没有产生很大的杂峰).


```{figure} ./imgs/default_data_vs_cleaned_data_improved.png
:name: cleaned_data_imporved_model

在新训练集上进一步改善模型的训练结果对比
```

```{figure} ./imgs/default_data_vs_cleaned_data_improved_valid.png
:name: cleaned_data_imporved_model_valid

在新训练集上进一步改善模型的验证结果对比
```
以上对比实验,可以看出, 清理过的数据集可以更好的支持更小规模的trans_encoder_layer, 相比在之前数据集上的原始模型的性能提升幅度甚至高达$30\%$. 

```{admonition} 初步结论
:class: tip

这组对比试验可以更清晰的看到,在新数据集上, 模型的训练波动更小, 收敛更快.
```

### 1.3 数据预处理时存在的问题
#### 1.3.1 训练数据分割
现在的训练集是通过分割Maxe产生的原始LOB数据产生, 分割方法是非重叠的滑动窗口法, 将原始时间步为50000的时序数据按100每段进行切分, 每条原始数据获得500条训练数据.
```{admonition} 冷启动问题
:class: warning

从前面对Maxe模拟器的xml文件的了解可以知道, 每一次模拟产生数据时都有一个上下文状态, 在SimLOB中, 该状态为:
    * bidVolume="10"
    * askVolume="10"
    * bidPrice="7514.9"
    * askPrice="7516.1"

一个直观的分析就是,这个LOB状态非常单薄, 如果在启动时产生一个超过10手的市价买单, 卖方就会被买空, 可能导致下一次卖单没有参考价格(系统认为目前最佳卖价为正无穷); 反之, 如果起始时产生超过10手的市价卖单, 买房会被买空, 导致下次买单没有参考价格(系统认为目前最佳买家为0). 

```


```{admonition} 解决方案
:class: tip

一个可行的方案是, 抛开原始数据的起始部分(比如前2000个时间步), 对剩下的部分进行采样.

采样的方案也可以不局限于非重叠的滑动窗口法, 可能以某个百分比重叠的滑动窗口更能抓住时序数据中的自相关属性.

```

#### 1.3.2 标准化方法
在SimLOB中, 对数据按列进行标准化, 具体方法如下:

```python
def standardize_cols(df, mean_list, std_list):

  for i,col in enumerate(df.columns):
      
    # 如果是时间列无法进行标准化！
    if col == 'time':
        continue
    arr = df[col].values
    arr = (arr - mean_list[i]) / std_list[i] 
    df[col] = arr

  return df
```

```{admonition} 讨论
:class: note
* **Z-score**是一种通用的机器学习数据预处理方法, 但是这样的方法在金融时序数据中是否有意义? 以价数据为例, 实际上订单只会造成某价格上量的上下波动, 但是在LOB数据中, 量数据会跟着价格的档位跳动. 
    * 比如, 1档买价 10.1,量10, 2档买价 10.2, 量1000, 3档买价10.3, 10, 当有卖单10.1卖出10手, 当前的1档买价变成10.2, 量1000, 2档买价10.3, 10; 虽然在系统中只成交了一笔非常小的订单,但是造成了LOB数据的巨幅改变. 
    * 如果以列作为数据Feature(以列为单位进行各种处理), 并用于训练模型,很可能会导致: 
        1. 训练过程不稳定
        2. 模型的输入输出缺乏可解释性
    * 如何合适地处理LOB数据, 对其进行符合现实情况地标准化, 还值得仔细研究.
* 是否应该按照价/量进行统一的标准化?
* 是否应该先对每一次模拟产生的LOB数据进行一次标准化, 再在训练数据集中对数据进行一次统一的标准化? 

```

```{admonition} 按列标准化
:class: warning
在 generate_data.py模块的整体标准化方法中, 关于'MPV'的整体标准化方法没有实现, 现在实验采用的是对于每次模拟产生的数据进行**按列标准化**之后进行分割并加入训练集. 
```

考虑到一次模拟产生的数据, 其上下文是一致的, 使用按单次模拟的价/量分别进行标准化是一个更好的选择.

### 1.4 其他细节

#### 1.4.1 模拟的效率

在使用Maxe编译得到的`TheSimulator`仿真器生成数据时, 有两个重要步骤:

1. 产生{ref}`XML 配置文件 <XML_file>`.
2. 通过`TheSimulator`读取该文件, 进行模拟后将输出保存在`.csv`文件中.

这两个步骤都需要对磁盘进行读写, 在大量生成数据时会产生两个问题:

```{admonition} 问题:
:class: warning

1. 读写效率: 对物理磁盘进行读写, I/O的效率相比内存读写要低很多, 特别是当Maxe采用多进程/线程的方式模拟多个Agent时

2. 在数据生成过程中循环使用相同的文件名保存xml配置文件, 单进程时不会影响, 如果多进程同时更新/读取同一个配置文件时会导致出错/重复. 
```

```{admonition} 解决办法:
:class: tip

使用python提供的虚拟文件系统包: `tempFiles`

  * 在内存中模拟文件句柄并返回给生成xml文件进程, 将xml配置写入虚拟文件, 同时在xml文件的输出配置项中写入另一个虚拟文件句柄.
  * 通过TheSimulator进行仿真, 数据会被写入上述虚拟文件中.
  * 这样做的好处有:
    * 虚拟文件名会自动进行hash不会出现相同文件名的情况.
    * 虚拟文件在内存中读写速度更快.
    * 可以直接将模拟结果读入pandas的DataFrame不进行中转.
    * 内存数据会按照系统资源使用情况被自动清理(也可以手动清理.)
```

## 2. 方法
### 2.2 Train Loss设计
在SimLOB中使用MESLoss作为自编码器的重构误差,用该Loss训练AE模型. 
```{admonition} Loss 问题
:class: error

同前面{ref}`关于LOB数据标准化的讨论 <lob_normalize>', 两个LOB数据之间的微小差异,可能导致MESLoss产生巨大差别.如图所示:

```

### 2.3 优化方法
在SimLOB工作中, 使用PSO对PGPS模型的6个参数进行优化, 优化的目标函数是:

\begin{align}
MSE(Encoder(RealLOB),Encoder(SimLOB))
\end{align}

```{admonition} 实验中的问题
:class: warning

以下问题可能是因为我重复实验室使用了不一样的参数进行优化得到的结果获得, 具体是什么问题还得完全复现原实验后再分析.

**问题1:**

已经训练好的Encoder在训练Loss没有使用正则化的情况下,(以一次运行为例) 输出的潜变量的均值约为$0.005$, 而其标准差约为$0.08$, 这一结果说明潜变量的分布非常集中(在图像上表现为在$0.005$附近细高的峰), 不知道在一般的AutoEncoder模型中, 这种分布是否属于正常现象, 待进一步确认.

**问题2:**

PSO方法种群大小为$40$, 最大优化代数为$100$, (以一次运行为例)优化开始时的Loss值为$0.043$, 在优化完成后该值为$0.039$, 相比随机的初始化值只优化了不到10%. 这可能是下面原因导致:

1. 该问题的优化难度非常大, 以致该参数设置下的PSO无法胜任
2. Encoder本身对原数据的表征不充分.

* 具体属于什么原因, 还有待下一步研究.

**问题3:**

* 结合上面两点, PSO的MSE损失函数代表的意义是每个元素差异的平均值, 在潜变量输出方差为$0.08$的前提下, 其优化后的损失值为$0.039$, 从直观上来说, 就是合成数据与待校准数据潜变量之间的差值达到了其绝对值的$50\%$, 这很难说PSO已经做了很好的优化了.
```


结合实验结果来看, 使用`PSO`方法, 种群大小设置为$40$, 迭代$100$轮, 其结果与随机产生4000组随即参数后选择其中最好的一组, 没有本质区别.

### 2.4 神经网络模型设计
SimLOB使用了多层神经网络, 如图`ref<SimLOB Structure>`所示:
(SimLOB Structure)=
![SimLOB神经网络结构](imgs/nn-structure.png)

在SimLOB的神经网络模型设计中, 没有对神经网络结构进行详细说明, 即:
1. 为什么使用了这样的网络结构? 
2. 如果不使用这样的结构会对结果有什么影响? (消融实验) 
3. 模型的超参数是如何确定的? (参数敏感性实验)


### 2.5 校准任务
在SimLOB中, 校准任务只是对不同参数的起始部分进行了对比, 即用一组参数启动Maxe模拟器, 获取其最最初的3600个LOB, 并基于这些LOB的Embedding向量, 使用`PSO`方法优化参数, Loss函数为Embedding向量的MSE. 

先不论`PSO`优化的效果, 这样校准显然不切实际. 这种校准只会在待校准数据本身就是Maxe模拟器产生的前 $3600$ 个数据时有效(高效), 因为两者产生的过程本身就是相同的. 但是这种方法没有任何实用价值, 因为待校准的数据(即使是模拟数据)不一定就是模拟器产生的前$3600$ 个数据, 而可能是一天中任意时刻开始的一段数据 (如第3601到7200的LOB数据), 这种形式的数据更接近现实中的校准需求. 

SimLOB中的校准本身就已经固定了Maxe模拟器的随机种子, 导致了模拟器的泛化能力大幅降低, 如果在校准时又固定其生成数据的时间段, 这样的校准任务即使能很好的完成也没有任何意义. 

```{admonition} 改进思路
:class: tip 
可以分为两层搜索, 在第一层使用PSO等方法对参数进行优化(全局搜索). 

对于每次迭代产生的最优个体(最优参数组)进行第二层搜索(局部优化): 用这组参数生成更多时序数据, 并沿着时间步搜索最符合待校准数据的时间段. 
```

### 2.6 ABM模型
在SimLOB中, 使用了Maxe仿真器对PGPS金融模型进行模拟, 通常可以认为该金融模型可以在一定程度上还原真实市场的Stylized Factor, 但是校准这个模型确是一个相当大的挑战. 一方面因为ABMs模型是从微观交互行为到宏观现象的复杂系统(又称为混沌系统), 在这种系统中微小的外界扰动( 如参数发生微小变化 )就会引起宏观现象的大幅改变 (蝴蝶效应), 用计算机术语表示就是模型高度非线性. 另一方面, 由计算机编程实现的ABMs模型是由伪随机数生成器驱动产生的随机现象, 在系统有轻微扰动下, 系统中原有的Agent行为可能产生巨大差异, 也会进一步提升系统的非线性程度. 

我进行了一个实验用于说明该现象, 即选定一组PGPS的参数, 每次固定其中5个数据, 另一个做最小步长的增加, 并对相邻的两组参数(即最微小扰动的两组)产生的数据进行预处理后计算其MSE, 图像如下所示:
```{figure} ./imgs/sensitive.png
---
height: 300px
name: directive-fig
---
参数敏感性实验
```
从上图可以看出, 对于标准化之后的数据来说, 这个MSE值的波动非常大. 也可以说明,即使是最轻微的扰动对于仿真结果来说也是完全不可预测的. 

虽然已经有大量黑盒优化方法可以不加前提地对问题进行优化, 但是对于金融校准问题来说, 每次评估参数需要花费大量时间进行仿真, 而所有参数都会对结果产生无法预期的影响( 直观来说,就是在非常差的解边上就可能有最优解 ). 以PSO为例, 从原理上来说, 这种优化方法与随机产生若干个解并选择其中的最优解无异; 而从结果上来看也是如此, 与初始种群fitness值相比, 100代的优化效果不超过25%, 这在优化问题中是非常少见的 (通常来说, 第一代随机参数的效果会非常差, 因此在若干代之后就会有明显提升, 在图像上表现很像一个典型的训练Loss曲线). 

此外, 从已有实验结果来看, 优化的效果与第一代结果也非常相关, 比如有第一代就达到0.3左右的, 也有第一代LOSS在9.0以上(为什么MSE会有9.0还需要进一步检查实验代码), 但是不管是哪种情况, PSO的优化效果都只有不到25%, 这也进一步说明, 无论是使用哪种方式进行校准 (即直接使用原始矩阵的MSE或是使用各种类型AutoEncoder), 对于结果的影响微乎其微, 其差异可能仅仅是随机性带来的结果波动. 

```{admonition} 使用其他优化方法
:class: warning
我尝试使用其他开箱即用的黑盒优化方法来优化该问题, 比如PYPOP7, 但是由于没有找到多线程设置, 导致一次优化时间非常长, 所以还没有进一步尝试. 
```

## 3. 实验设置



## 4. 代码实现

### 4.1 优化部分
```{admonition} 校准时的数据生成过程实现问题:
:class: error

* 在优化过程中, 调用TheSimulator生成LOB文件, 这个文件会写入磁盘, 然后由下一行代码将该文件内容读入pandas.DataFrame中. 这会造成一个读写的时间差, 如果是系统中原本不存在的csv, 这个过程必然会报错, 提示文件不存在.
* 该实现的解决办法是循环使用几个系统中已存在文件名来存储数据, 但这样做就可能出现常见的同时读写问题, 大概率是读到之前的csv文件( 如果写的过程中读文件可能发生不可预料的错误 ), 如果文件数量一次迭代所需的数量相同, 基本上可以认为 `t`时刻优化用的是`t-1`时刻的数据, 约等于少一次优化. 如果数量少于所需数量, 可能严重影响优化过程.
```

```{admonition} 实现效率:
:class: warning

* 读写物理文件系统的效率问题.
* `to_latent`方法计算Loss时使用了to('cpu')将数据迁移到cpu上再用自己实现的mse方法进行计算, 相比直接在gpu上, 利用内置函数算完mse,再将结果迁移回cpu(供PSO在cpu上使用), 效率会大打折扣.
* 在使用Encoder计算latent的时候没有使用`with torch.no_grad()`或其他类似的操作让系统不记录梯度值, 效率会有所降低.
* `data_classification_tensor`方法实现的实际上就是一个reshape方法, 自己重写效率很低.

```

## 5. 结果讨论

