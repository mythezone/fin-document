# NewLOB实验设计

## 1. 为什么要特别针对LOB数据进行表征？

1. 表征的功能是什么？
   * 对金融领域有什么贡献？
     * 其他的模型表征（手工抽取，任务绑定）
     * 提供LOB数据特征抽取的模型
 
2. LOB数据表征的难点是什么？
   * AI领域的Contribution是什么？
     * LOB数据有自身的特点， 其特征的重要程度是不一样的，因此需要针对LOB数据设计对应的方法/模型（scale也不一样）
     * 价格特征之间有大小的约束，从小到大应该是BestBid10<BestBid9...<
     * LOB数据维度相比其他领域任务来说更高
     * LOB具有复杂的时序关系，比如（是否具有自相关性、数据是否独立同分布）
     * 提供了新的问题
     * 新的数据集


$$
LOB^{m\times t}
$$

其中， m是特征数（在LOB中为40）， t为诗序数据的长度。
通用数据的归一化方法是对每一个feature进行归一化即：

$$
LOB^i= \frac{LOB^{i,j}-mean(LOB^i)}{std(LOB^i)}
$$
  
## 2. 已经有很多模型在处理LOB数据了， 为什么还要做这个表征研究？
   1. 隔离下游任务（通用化）
   2. 缺乏通用化表示的专门的研究
   3. SimLOB是第一篇， 但是还有不足之处

## 3. SimLOB还有什么不足？
   1. 没有针对前述的challenge进行设计


## 4. 本文模型的设计：
   1. Weigthed Loss 设计
   2. 不同Normalization对下游任务（模型）的影响
   3. 在Loss 中加正则项（或者修改网络结构）
   4. 其他改进

## 5. 对比方法选择
1. Baseline方法:
   1. CNN
   2. LSTM
   3. Transformer - Attention is All You Need [NeurIPS 2017].
2. SOTA方法, 包括Time Series Library中排行榜前三中的几个优秀模型:
   1. TimesNet: TimesNet - TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis [ICLR 2023].
   2. Non-stationary Transformer - Non-stationary Transformers: Exploring the Stationarity in Time Series Forecasting [NeurIPS 2022]
   3. iTransformer - iTransformer: Inverted Transformers Are Effective for Time Series Forecasting [ICLR 2024] 
   4. TimeMixer - TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting [ICLR 2024]
3. LOB方法, 包括几个专门针对LOB数据进行处理的模型:
   1. DeepLOB
   2. TransLOB

## 任务选择
1. LOB Representation
   1. 实验目的:
      * 研究模型表征LOB的能力, 是否能够将高维LOB序列数据无损映射到低维, 以有效降低下游任务的复杂度. 
   2. 实验方法:
      1. 通过模型的Encoder将LOB序列映射到相同长度的隐变量.
      2. 再使用相同的Decoder对该隐变量解码得到的LOB序列, 与原LOB之间的差异.
   3. 评估标准:
      1. MSELoss.
      2. PriceLoss, VolumeLoss.
      3. WeightedPriceLoss, WeightedVolumeLoss.
      4. MoneyLoss.
   4. 预期结果:
      1. 相同模型使用不同的损失函数进行训练的结果对比(并比较其他评估标准), WeightedXX系列的效果应该优于其他评估方法的效果. 
      2. 我们的模型在WeightedXX损失函数要优于大部分方法(至少与SOTA保持在同一水平), 并且结构更简单.
2. 预测任务
   1. 实验目的:
      * 验证使用训练好的模型Encoder对LOB数据进行处理后得到的隐向量作为特征是否能更好的服务于下游任务.
   2. 实验方法:
      1. 手工提取的特征\原始LOB\经模型表征后的特征, 分别放到相同的预测模型中进行预测.
      2. 经不同模型Encoder的特征, 用相同的Decoder进行预测.
      3. 使用不同的AE针对预测任务直接训练, 对比任务效果.
      4. 将模型的Encoder都替换成我们的表征
   3.  预期结果:
       1.  表征后的模型训练收敛更快, 参数更少, 性能更优
       2.  我们的Decoder模型相比其他模型对于同样的表征特征来说, 性能更好.
       3.  我们的模型的表征更好
       4.  对任务进行End-to-end的训练耗时更多, 效果持平(或稍微好一点).
3. 异常检测



4.  校准任务
    1.  实验目的:
        1.  相比预测\差值\异常检测等常规时序数据相关任务, 校准任务需要对产生时序数据的模型(仿真器)进行反向推演, 其复杂程度(难度)更高, 在校准过程中更是需要大量数据, 一个好的表示模型可以大幅降低校准任务中数据的维度, 降低校准所需的计算资源和提高校准的精度.
    2.  实验方法:
        1.  使用不同模型对数据表征后的特征向量, 用同样的优化方法(比如PSO等)进行优化
    3.  预期结果:
        1.  我们的模型校准的结果和速度比其他模型都好, 或者至少在其中一个指标上要更好.

## 实验一: 对比各AE模型对LOB重构能力
