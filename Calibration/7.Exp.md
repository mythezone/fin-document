# NewLOB实验设计

## 对比方法选择
1. Baseline方法:
   1. CNN
   2. LSTM
   3. Transformer - Attention is All You Need [NeurIPS 2017].
2. SOTA方法, 包括Time Series Library中排行榜前三中的几个优秀模型:
   1. TimesNet: TimesNet - TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis [ICLR 2023].
   2. Non-stationary Transformer - Non-stationary Transformers: Exploring the Stationarity in Time Series Forecasting [NeurIPS 2022]
   3. iTransformer - iTransformer: Inverted Transformers Are Effective for Time Series Forecasting [ICLR 2024] 
   4. TimeMixer - TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting [ICLR 2024]
3. LOB方法, 包括几个专门针对LOB数据进行处理的模型:
   1. DeepLOB
   2. TransLOB

## 任务选择
1. LOB Representation
   1. 实验目的:
      * 研究模型表征LOB的能力, 是否能够将高维LOB序列数据无损映射到低维, 以有效降低下游任务的复杂度. 
   2. 实验方法:
      1. 通过模型的Encoder将LOB序列映射到相同长度的隐变量.
      2. 再使用相同的Decoder对该隐变量解码得到的LOB序列, 与原LOB之间的差异.
   3. 评估标准:
      1. MSELoss
      2. PriceLoss, VolumeLoss
      3. WeightedPriceLoss, WeightedVolumeLoss
      4. MoneyLoss
   4. 预期结果:
      1. 相同模型使用不同的损失函数进行训练的结果对比(并比较其他评估标准), WeightedXX系列的效果应该优于其他评估方法的效果. 
      2. 我们的模型在WeightedXX损失函数要优于大部分方法(至少与SOTA保持在同一水平), 并且结构更简单.
2. 预测任务
   1. 实验目的:
      * 验证使用训练好的模型Encoder对LOB数据进行处理后得到的隐向量作为特征是否能更好的服务于下游任务.
   2. 实验方法:
      1. 手工提取的特征\原始LOB\经模型表征后的特征, 分别放到相同的预测模型中进行预测.
      2. 经不同模型Encoder的特征, 用相同的Decoder进行预测.
      3. 使用不同的AE针对预测任务直接训练, 对比任务效果.
      4. 将模型的Encoder都替换成我们的表征
   3.  预期结果:
       1.  表征后的模型训练收敛更快, 参数更少, 性能更优
       2.  我们的Decoder模型相比其他模型对于同样的表征特征来说, 性能更好.
       3.  我们的模型的表征更好
       4.  对任务进行End-to-end的训练耗时更多, 效果持平(或稍微好一点).
3. 异常检测

4. 


4.  校准任务
    1.  实验目的:
        1.  相比预测\差值\异常检测等常规时序数据相关任务, 校准任务需要对产生时序数据的模型(仿真器)进行反向推演, 其复杂程度(难度)更高, 在校准过程中更是需要大量数据, 一个好的表示模型可以大幅降低校准任务中数据的维度, 降低校准所需的计算资源和提高校准的精度.
    2.  实验方法:
        1.  使用不同模型对数据表征后的特征向量, 用同样的优化方法(比如PSO等)进行优化
    3.  预期结果:
        1.  我们的模型校准的结果和速度比其他模型都好, 或者至少在其中一个指标上要更好.

## 实验一: 对比各AE模型对LOB重构能力
